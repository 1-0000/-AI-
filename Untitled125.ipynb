{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled125.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbwP/X3WP2xOqTU7NsVDVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artjow/-AI-/blob/main/Untitled125.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFAz8EWbNdsL",
        "outputId": "72614d8a-7985-4aaf-a530-0d008039ef77"
      },
      "source": [
        "!git clone https://github.com/naoto0804/pytorch-AdaIN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-AdaIN'...\n",
            "remote: Enumerating objects: 293, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 293 (delta 2), reused 0 (delta 0), pack-reused 285\u001b[K\n",
            "Receiving objects: 100% (293/293), 7.78 MiB | 38.67 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcSjuNE9OBQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c5d565a6-025f-43fa-89c3-674bac9fec2e"
      },
      "source": [
        "numpy==1.17.2\n",
        "Pillow==8.2.0\n",
        "pkg-resources==0.0.0\n",
        "protobuf==3.9.1\n",
        "six==1.12.0\n",
        "tensorboardX==1.8\n",
        "torch==1.2.0\n",
        "torchvision==0.4.0\n",
        "tqdm==4.35.0\n",
        "opencv-python==4.4.0.46\n",
        "imageio==2.9.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-2d3a130578ee>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    numpy==1.17.2\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikI2WWjVNfnL"
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def calc_mean_std(feat, eps=1e-5):\n",
        "    # eps is a small value added to the variance to avoid divide-by-zero.\n",
        "    size = feat.size()\n",
        "    assert (len(size) == 4)\n",
        "    N, C = size[:2]\n",
        "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
        "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
        "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
        "    return feat_mean, feat_std\n",
        "\n",
        "\n",
        "def adaptive_instance_normalization(content_feat, style_feat):\n",
        "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
        "    size = content_feat.size()\n",
        "    style_mean, style_std = calc_mean_std(style_feat)\n",
        "    content_mean, content_std = calc_mean_std(content_feat)\n",
        "\n",
        "    normalized_feat = (content_feat - content_mean.expand(\n",
        "        size)) / content_std.expand(size)\n",
        "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)\n",
        "\n",
        "\n",
        "def _calc_feat_flatten_mean_std(feat):\n",
        "    # takes 3D feat (C, H, W), return mean and std of array within channels\n",
        "    assert (feat.size()[0] == 3)\n",
        "    assert (isinstance(feat, torch.FloatTensor))\n",
        "    feat_flatten = feat.view(3, -1)\n",
        "    mean = feat_flatten.mean(dim=-1, keepdim=True)\n",
        "    std = feat_flatten.std(dim=-1, keepdim=True)\n",
        "    return feat_flatten, mean, std\n",
        "\n",
        "\n",
        "def _mat_sqrt(x):\n",
        "    U, D, V = torch.svd(x)\n",
        "    return torch.mm(torch.mm(U, D.pow(0.5).diag()), V.t())\n",
        "\n",
        "\n",
        "def coral(source, target):\n",
        "    # assume both source and target are 3D array (C, H, W)\n",
        "    # Note: flatten -> f\n",
        "\n",
        "    source_f, source_f_mean, source_f_std = _calc_feat_flatten_mean_std(source)\n",
        "    source_f_norm = (source_f - source_f_mean.expand_as(\n",
        "        source_f)) / source_f_std.expand_as(source_f)\n",
        "    source_f_cov_eye = \\\n",
        "        torch.mm(source_f_norm, source_f_norm.t()) + torch.eye(3)\n",
        "\n",
        "    target_f, target_f_mean, target_f_std = _calc_feat_flatten_mean_std(target)\n",
        "    target_f_norm = (target_f - target_f_mean.expand_as(\n",
        "        target_f)) / target_f_std.expand_as(target_f)\n",
        "    target_f_cov_eye = \\\n",
        "        torch.mm(target_f_norm, target_f_norm.t()) + torch.eye(3)\n",
        "\n",
        "    source_f_norm_transfer = torch.mm(\n",
        "        _mat_sqrt(target_f_cov_eye),\n",
        "        torch.mm(torch.inverse(_mat_sqrt(source_f_cov_eye)),\n",
        "                 source_f_norm)\n",
        "    )\n",
        "\n",
        "    source_f_transfer = source_f_norm_transfer * \\\n",
        "                        target_f_std.expand_as(source_f_norm) + \\\n",
        "                        target_f_mean.expand_as(source_f_norm)\n",
        "\n",
        "    return source_f_transfer.view(source.size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "FlI3lFjRNnlu",
        "outputId": "a6d559df-7d72-4731-e3b8-db3a752ab4b4"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "from function import adaptive_instance_normalization as adain\n",
        "from function import calc_mean_std\n",
        "\n",
        "decoder = nn.Sequential(\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 3, (3, 3)),\n",
        ")\n",
        "\n",
        "vgg = nn.Sequential(\n",
        "    nn.Conv2d(3, 3, (1, 1)),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(3, 64, (3, 3)),\n",
        "    nn.ReLU(),  # relu1-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(),  # relu1-2\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 128, (3, 3)),\n",
        "    nn.ReLU(),  # relu2-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(),  # relu2-2\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),  # relu3-4\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-1, this is the last layer used\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu4-4\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu5-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu5-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(),  # relu5-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU()  # relu5-4\n",
        ")\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Net, self).__init__()\n",
        "        enc_layers = list(encoder.children())\n",
        "        self.enc_1 = nn.Sequential(*enc_layers[:4])  # input -> relu1_1\n",
        "        self.enc_2 = nn.Sequential(*enc_layers[4:11])  # relu1_1 -> relu2_1\n",
        "        self.enc_3 = nn.Sequential(*enc_layers[11:18])  # relu2_1 -> relu3_1\n",
        "        self.enc_4 = nn.Sequential(*enc_layers[18:31])  # relu3_1 -> relu4_1\n",
        "        self.decoder = decoder\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "        # fix the encoder\n",
        "        for name in ['enc_1', 'enc_2', 'enc_3', 'enc_4']:\n",
        "            for param in getattr(self, name).parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    # extract relu1_1, relu2_1, relu3_1, relu4_1 from input image\n",
        "    def encode_with_intermediate(self, input):\n",
        "        results = [input]\n",
        "        for i in range(4):\n",
        "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
        "            results.append(func(results[-1]))\n",
        "        return results[1:]\n",
        "\n",
        "    # extract relu4_1 from input image\n",
        "    def encode(self, input):\n",
        "        for i in range(4):\n",
        "            input = getattr(self, 'enc_{:d}'.format(i + 1))(input)\n",
        "        return input\n",
        "\n",
        "    def calc_content_loss(self, input, target):\n",
        "        assert (input.size() == target.size())\n",
        "        assert (target.requires_grad is False)\n",
        "        return self.mse_loss(input, target)\n",
        "\n",
        "    def calc_style_loss(self, input, target):\n",
        "        assert (input.size() == target.size())\n",
        "        assert (target.requires_grad is False)\n",
        "        input_mean, input_std = calc_mean_std(input)\n",
        "        target_mean, target_std = calc_mean_std(target)\n",
        "        return self.mse_loss(input_mean, target_mean) + \\\n",
        "               self.mse_loss(input_std, target_std)\n",
        "\n",
        "    def forward(self, content, style, alpha=1.0):\n",
        "        assert 0 <= alpha <= 1\n",
        "        style_feats = self.encode_with_intermediate(style)\n",
        "        content_feat = self.encode(content)\n",
        "        t = adain(content_feat, style_feats[-1])\n",
        "        t = alpha * t + (1 - alpha) * content_feat\n",
        "\n",
        "        g_t = self.decoder(t)\n",
        "        g_t_feats = self.encode_with_intermediate(g_t)\n",
        "\n",
        "        loss_c = self.calc_content_loss(g_t_feats[-1], t)\n",
        "        loss_s = self.calc_style_loss(g_t_feats[0], style_feats[0])\n",
        "        for i in range(1, 4):\n",
        "            loss_s += self.calc_style_loss(g_t_feats[i], style_feats[i])\n",
        "        return loss_c, loss_s\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-85a57a939f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madaptive_instance_normalization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0madain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_mean_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'function'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSsBUm_fNuD5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}